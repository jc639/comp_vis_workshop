{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db97f944-d142-4a6b-9a42-e09b22020657",
   "metadata": {},
   "source": [
    "# Exercise Solutions\n",
    "\n",
    "These are some solutions to the exercises in Workshop_5, these are not the only way to solve the exercises but are more intended as guide. \n",
    "***\n",
    "1. Can we use a different backbone? Some very simple changes would be to try a larger ResNet, the number 18 in the one we have used refers to the number of layers but there are versions with 34, 50, 101 and 152 layers. Have a look at the cell defining the model, specifically the lines:\n",
    "- `from torchvision.models import resnet18, resnet`\n",
    "- `self.backbone = nn.Sequential(*list(resnet18(weights=resnet.ResNet18_Weights.DEFAULT).children())[:-1])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d32048-dd60-417c-9954-501401cb30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SOLUTION\n",
    "# IN the CVModel definition we just need to import and change the resnet number to load a larger model.\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet34, resnet\n",
    "\n",
    "class CVModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(*list(resnet34(weights=resnet.ResNet34_Weights.DEFAULT).children())[:-1])\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.classifier = nn.Linear(512, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.classifier(x)\n",
    "        \n",
    "\n",
    "model = CVModel(n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28636244-b29f-4cc9-871a-eeba6ee6e160",
   "metadata": {},
   "source": [
    "***\n",
    "2. We have evaluated the model on the validation set and returned an overall accuracy score but does this represent the best way to validate the performance of the model? Is there any other metrics we could calculate on this dataset?\n",
    "\n",
    "Use this code to obtain all predictions and labels for the validation set and think about what else you could calculate:\n",
    "```python\n",
    "preds = []\n",
    "labels = []\n",
    "for x, y in val_dl:\n",
    "    logits, softmax, argmax = predict(model, x)\n",
    "    preds.extend(argmax.tolist())\n",
    "    labels.extend(y.tolist())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716334d3-ce57-4bbd-a56d-6a9f6616c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Solution\n",
    "# We could look at the precision and recall for each class given the above\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27612c28-790e-4ffb-be69-d2e857a71d0f",
   "metadata": {},
   "source": [
    "***\n",
    "3. What happens if the normalization steps are removed from the transform pipeline, how does this affect the values of `x` in the batches from the training dataloader? How does this affect the model training?\n",
    "\n",
    "To do this just comment out the `v2.Normalization` in the transform pipelines. You will likely find it affects the accuracy and that it goes but probably not by a huge amount, as we are finetuning the model the input layer weights are also being adapted during training so they should be able to compensate.\n",
    "\n",
    "***\n",
    "4. Are there any other transforms that could be added to the training transform pipeline - have a look [here](https://pytorch.org/vision/stable/transforms.html#v2-api-reference-recommended) and try a few!\n",
    "\n",
    "Really this one can be any that you find interesting. Just add them to the following cell in the notebook:\n",
    "```python\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "train_transforms = v2.Compose(\n",
    "    [\n",
    "        SquareImage(),\n",
    "        v2.Resize(224),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.ToImageTensor(),\n",
    "        v2.ConvertImageDtype(),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = v2.Compose(\n",
    "    [\n",
    "        SquareImage(),\n",
    "        v2.Resize(224),\n",
    "        v2.ToImageTensor(),\n",
    "        v2.ConvertImageDtype(),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "5. When we use the pretrained model we are 'cheating' a little bit - it has been trained on ImageNet and the image net dataset includes many animals including dogs and cats so the model actually already knows how to extract features. What happens if we don't use a pretrained model, take a look at this line in the model definition and modify it so we start with a completely fresh model:\n",
    "- `self.backbone = nn.Sequential(*list(resnet18(weights=resnet.ResNet18_Weights.DEFAULT).children())[:-1])`\n",
    "\n",
    "How does this change the accuracy achieved in 5 epochs?\n",
    "\n",
    "Here you just need to change the `weights=...` in the above line in the `CVModel` definition.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18, resnet\n",
    "\n",
    "class CVModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(*list(resnet18(weights=None).children())[:-1])\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.classifier = nn.Linear(512, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.classifier(x)\n",
    "        \n",
    "\n",
    "model = CVModel(n_classes=3)\n",
    "```\n",
    "\n",
    "You are now training a completely fresh neural network, it will likely not achieve a very good accuracy in just 5 epochs and will require training for much longer/require much more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1de60a-f986-45d3-80fb-d533a9f1c604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
